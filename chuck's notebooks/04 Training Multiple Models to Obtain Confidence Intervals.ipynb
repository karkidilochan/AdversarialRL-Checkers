{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Multiple Models to Obtain Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics for today:\n",
    "1. Linear model code from last time\n",
    "2. Irregularly Spaced Data\n",
    "1. Divide data into training and testing sets\n",
    "1. Multiple Models to Estimate Uncertainties and Confidence Intervals\n",
    "1. 90% confidence interval for predictions of all samples\n",
    "1. Confidence intervals of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model code from last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from topic_banner import new_topic\n",
    "new_topic('Linear model code from last time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_powers(X, max_power):\n",
    "    return np.hstack([X ** p for p in range(1, max_power + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, T, n_epochs, rho):\n",
    "    \n",
    "    means = X.mean(0)\n",
    "    stds = X.std(0)\n",
    "    # Replace stds of 0 with 1 to avoid dividing by 0.\n",
    "    stds[stds == 0] = 1\n",
    "    Xst = (X - means) / stds\n",
    "    \n",
    "    Xst = np.insert(Xst, 0, 1, axis=1)  # Insert column of 1's as first column in Xst\n",
    "    \n",
    "    # n_samples, n_inputs = Xst.shape[0]\n",
    "    n_samples, n_inputs = Xst.shape\n",
    "    \n",
    "    # Initialize weights to all zeros\n",
    "    W = np.zeros((n_inputs, 1))  # matrix of one column\n",
    "    \n",
    "    # Repeat updates for all samples for multiple passes, or epochs,\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Update weights once for each sample.\n",
    "        for n in range(n_samples):\n",
    "        \n",
    "            # Calculate prediction using current model, w.\n",
    "            #    n:n+1 is used instead of n to preserve the 2-dimensional matrix structure\n",
    "            Y = Xst[n:n + 1, :] @ W\n",
    "            \n",
    "            # Update w using negative gradient of error for nth sample\n",
    "            W += rho * Xst[n:n + 1, :].T * (T[n:n + 1, :] - Y)\n",
    "                \n",
    "    # Return a dictionary containing the weight matrix and standardization parameters.\n",
    "    return {'W': W, 'means' : means, 'stds' :stds, 'max_power': max_power}\n",
    "\n",
    "def use(model, X):\n",
    "    Xst = (X - model['means']) / model['stds']\n",
    "    Xst = np.insert(Xst, 0, 1, axis=1)\n",
    "    Y = Xst @ model['W']\n",
    "    return Y\n",
    "\n",
    "def rmse(A, B):\n",
    "    return np.sqrt(np.mean( (A - B)**2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Irregularly Spaced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from topic_banner import new_topic\n",
    "new_topic('Irregularly Spaced Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function of a single variable, $x$, which we will apply to three different spans of $x$ values.\n",
    "\n",
    "$$ -1 + 10 e^{0.1 x} + 0.1 x^2 - 0.02 x^3 + r$$\n",
    "\n",
    "where $r$ is from a standard Normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_each_section = 40\n",
    "\n",
    "ns = n_samples_each_section\n",
    "X = np.hstack((np.linspace(-8, -5, num=ns),\n",
    "               np.linspace(0, 3, num=ns),\n",
    "               np.linspace(6, 10, num=ns))).reshape(3 * ns, 1)\n",
    "T = -1 + 10 * np.exp(0.1 * X)\n",
    "T += 0.1 * X**2\n",
    "T += - 0.02 * X**3\n",
    "T += 1.0 * np.random.normal(size=(3 * ns, 1))\n",
    "X.shape, T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, T, '.-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topic('Divide data into training and testing sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(7.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_fraction = 0.8\n",
    "\n",
    "n_rows = X.shape[0]\n",
    "row_indices = np.arange(n_rows)\n",
    "np.random.shuffle(row_indices)\n",
    "n_train = round(n_rows * training_fraction)\n",
    "n_test = n_rows - n_train\n",
    "\n",
    "Xtrain = X[row_indices[:n_train], :]\n",
    "Ttrain = T[row_indices[:n_train], :]\n",
    "Xtest = X[row_indices[n_train:], :]\n",
    "Ttest = T[row_indices[n_train:], :]\n",
    "\n",
    "Xtrain.shape, Ttrain.shape, Xtest.shape, Ttest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Xtrain[:, 0], Ttrain, 'o', label='Train')\n",
    "plt.plot(Xtest[:, 0], Ttest, 'ro', label='Test')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Models to Estimate Uncertainties and Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topic('Multiple Models to Estimate Uncertainties and Confidence Intervals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make models based on bootstrap samples of training data.  `models` will be list of models, one for each bootstrap sample.\n",
    "\n",
    "For each bootstrap sample of our training data we will randomly choose `n_train` samples **with replacement**.  The following code cell illustrates how to create 20 bootstrap samples, each with 10 samples.  The bootstrap samples are defined as row indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(list(range(11)), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_power = 1\n",
    "n_models = 1000\n",
    "max_power = 1  # linear model\n",
    "\n",
    "Xtrain = X[row_indices[:n_train], :]\n",
    "Xtest = X[row_indices[n_train:], :]\n",
    "Xtrain = make_powers(Xtrain, max_power)\n",
    "Xtest = make_powers(Xtest, max_power)\n",
    "\n",
    "n_epochs = 1000\n",
    "rho = 0.01\n",
    "\n",
    "n_models = 10\n",
    "\n",
    "models = []\n",
    "for model_i in range(n_models):\n",
    "    train_rows = np.random.choice(list(range(n_train)), n_train)\n",
    "    Xtrain_boot = Xtrain[train_rows, :]\n",
    "    Ttrain_boot = Ttrain[train_rows, :]\n",
    "    model = train(Xtrain_boot, Ttrain_boot, n_epochs, rho)\n",
    "    models.append(model)\n",
    "    print(f'Model {model_i}', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply all of the models to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use(models[0], Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_all = []\n",
    "for model in models:\n",
    "    Y_all.append( use(model, Xtest) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `numpy.array` for all outputs of all models so we can easily calculate the mean for each test sample over all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Y_all).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Use `numpy.squeeze` to wring out the \"unused\" dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Y_all).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all = np.array(Y_all).squeeze().T  # I like putting each model's output in a column, so `Y_all` now has each model's output for a sample in a row.\n",
    "Ytest = np.mean(Y_all, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_test = np.sqrt(np.mean((Ytest - Ttest)**2))\n",
    "print(f'Test RMSE is {RMSE_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 200\n",
    "Xplot = np.linspace(-10, 12, n_plot).reshape(n_plot, 1)\n",
    "Xplot_powers = make_powers(Xplot, max_power)\n",
    "Ys = []\n",
    "for model in models:\n",
    "    Yplot = use(model, Xplot_powers)\n",
    "    Ys.append(Yplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Ys).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ys = np.array(Ys).squeeze().T\n",
    "Ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(Xtrain[:, 0], Ttrain, 'o')\n",
    "plt.plot(Xtest[:, 0], Ttest, 'o')\n",
    "plt.plot(Xplot, Ys, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do again with nonlinear terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_power = 8\n",
    "Xtrain = X[row_indices[:n_train], :]\n",
    "Xtest = X[row_indices[n_train:], :]\n",
    "Xtrain = make_powers(Xtrain, max_power)\n",
    "Xtest = make_powers(Xtest, max_power)\n",
    "\n",
    "n_epochs = 2000\n",
    "rho = 0.02\n",
    "\n",
    "n_models = 100 \n",
    "\n",
    "models = []\n",
    "for model_i in range(n_models):\n",
    "    train_rows = np.random.choice(list(range(n_train)), n_train)\n",
    "    Xtrain_boot = Xtrain[train_rows, :]\n",
    "    Ttrain_boot = Ttrain[train_rows, :]\n",
    "    model = train(Xtrain_boot, Ttrain_boot, n_epochs, rho)\n",
    "    models.append(model)\n",
    "    print(f'Model {model_i}', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 200\n",
    "Xplot = np.linspace(-10, 12, n_plot).reshape(n_plot, 1)\n",
    "Xplot_powers = make_powers(Xplot, max_power)\n",
    "Ys = []\n",
    "for model in models:\n",
    "    Yplot = use(model, Xplot_powers)\n",
    "    Ys.append(Yplot)\n",
    "\n",
    "Ys = np.array(Ys).squeeze().T\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(Xtrain[:, 0], Ttrain, 'o')\n",
    "plt.plot(Xtest[:, 0], Ttest, 'o')\n",
    "plt.plot(Xplot, Ys, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 90% confidence interval for predictions of all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_topic('90% confidence interval for predictions of all samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_plot = 200\n",
    "Xplot = np.linspace(-10, 12, n_plot).reshape(n_plot, 1)\n",
    "Xplot_powers = make_powers(Xplot, max_power)\n",
    "Ys = []\n",
    "for model in models:\n",
    "    Yplot = use(model, Xplot_powers)\n",
    "    Ys.append(Yplot)\n",
    "\n",
    "Ys = np.array(Ys).squeeze().T\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(Xtrain[:, 0], Ttrain, 'o', alpha=0.2)\n",
    "plt.plot(Xtest[:, 0], Ttest, 'o', alpha=0.2)\n",
    "\n",
    "plt.fill_between(Xplot.reshape(-1), Ys.min(axis=-1), Ys.max(axis=-1),\n",
    "                color='#fded08')\n",
    "\n",
    "middle = len(models) // 2\n",
    "plt.plot(Xplot, Ys[:, middle]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence intervals of the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_topic('Confidence intervals of the weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to evaluate the significance of each input by considering the weights on each input across the models. Let's say we want the 90% confidence interval. First, let's collect the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Ws = [model['W'] for model in models]\n",
    "len(all_Ws), all_Ws[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_Ws).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Ws = np.array(all_Ws).squeeze()\n",
    "all_Ws.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we must sort the weight values independently for each input to find the 5% and 95% quantile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.random.randint(-10, 10, size=50).reshape(10, 5)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(Z, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Ws = np.sort(all_Ws, axis=0)\n",
    "low_high = all_Ws[[4, 94], :].T\n",
    "low_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(low_high):\n",
    "    if i == 0:\n",
    "        print(f'Bias w   Low {row[0]:6.2f} High {row[1]:6.2f}')\n",
    "    else:\n",
    "        print(f'Power {i + 1:2} Low {row[0]:6.2f} High {row[1]:6.2f}')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
